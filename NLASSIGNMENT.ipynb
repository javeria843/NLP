{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91022397-5970-4d95-9dd9-0c2aeaa54e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ba6d925-3605-4f79-b78a-bd862ff1de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= {\n",
    "  \"Movies\": [\n",
    "    {\n",
    "      \"genre\": 1,\n",
    "      \"name\": \"Coffee & Kareem\",\n",
    "      \"description\": \"A 12-year-old boy tries to scare away his mother's new boyfriend, a police officer, but his plan backfires, exposing them to a criminal network.\"\n",
    "    },\n",
    "    {\n",
    "      \"genre\": 2,\n",
    "      \"name\": \"Unfinished Business\",\n",
    "      \"description\": \"A businessman starts his own company and travels to Europe with his associates to close an important deal, facing unexpected challenges.\"\n",
    "    },\n",
    "    {\n",
    "      \"genre\": 3,\n",
    "      \"name\": \"Tooth Fairy\",\n",
    "      \"description\": \"A tough hockey player is sentenced to serve as a real-life tooth fairy for a week after discouraging a child's dreams.\"\n",
    "    },\n",
    "    {\n",
    "      \"genre\": 4,\n",
    "      \"name\": \"Look Who's Talking Too\",\n",
    "      \"description\": \"In this sequel, a couple deals with the arrival of a new baby, leading to sibling rivalry and humorous situations.\"\n",
    "    },\n",
    "    {\n",
    "      \"genre\": 5,\n",
    "      \"name\": \"Drive-Away Dolls\",\n",
    "      \"description\": \"Two friends embark on a road trip seeking a fresh start but become entangled in a criminal scheme.\"\n",
    "    },\n",
    "    {\n",
    "      \"genre\": 6,\n",
    "      \"name\": \"Life After Beth\",\n",
    "      \"description\": \"A young man's deceased girlfriend returns from the dead, leading to unexpected and bizarre consequences.\"\n",
    "    },\n",
    "    {\n",
    "      \"genre\": 7,\n",
    "      \"name\": \"40 Days and 40 Nights\",\n",
    "      \"description\": \"After a painful breakup, a man vows to abstain from any sexual activity for Lent, but complications arise when he meets someone new.\"\n",
    "    },\n",
    "    {\n",
    "      \"genre\": 8,\n",
    "      \"name\": \"The Misfits\",\n",
    "      \"description\": \"A group of modern-day Robin Hoods recruits a renowned thief to help them pull off a heist targeting a corrupt businessman.\"\n",
    "    },\n",
    "    {\n",
    "      \"genre\": 9,\n",
    "      \"name\": \"Premature\",\n",
    "      \"description\": \"A high school student relives the same day repeatedly, trying to get his first sexual experience right.\"\n",
    "    },\n",
    "    {\n",
    "      \"genre\": 10,\n",
    "      \"name\": \"The Last Days on Mars\",\n",
    "      \"description\": \"Astronauts on Mars discover a deadly organism that turns them into zombie-like creatures.\"\n",
    "    },\n",
    "    {\n",
    "      \"genre\": 11,\n",
    "      \"name\": \"Stolen\",\n",
    "      \"description\": \"A former thief has 12 hours to find $10 million and rescue his kidnapped daughter from his former partner.\"\n",
    "    },\n",
    "    {\n",
    "      \"genre\": 12,\n",
    "      \"name\": \"The Haunting\",\n",
    "      \"description\": \"Participants in a sleep study at a haunted mansion experience terrifying supernatural events.\"\n",
    "    },\n",
    "    {\n",
    "      \"genre\": 13,\n",
    "      \"name\": \"Be Cool\",\n",
    "      \"description\": \"A mobster enters the music industry, facing challenges as he tries to manage a new artist's career.\"\n",
    "    },\n",
    "    {\n",
    "      \"genre\": 14,\n",
    "      \"name\": \"Turistas\",\n",
    "      \"description\": \"Backpackers stranded in Brazil fall victim to a sinister organ-harvesting operation.\"\n",
    "    },\n",
    "    {\n",
    "      \"genre\": 15,\n",
    "      \"name\": \"Teenage Mutant Ninja Turtles III\",\n",
    "      \"description\": \"The turtles travel back in time to 17th-century Japan to rescue their friend and find themselves in the middle of a samurai conflict.\"\n",
    "    }\n",
    "  ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb7ff1cd-7430-4e1e-b806-da21bdc17795",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data[\"Movies\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "923520e1-72b1-4f25-a48a-b1bff5d8299f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Coffee &amp; Kareem</td>\n",
       "      <td>A 12-year-old boy tries to scare away his moth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Unfinished Business</td>\n",
       "      <td>A businessman starts his own company and trave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tooth Fairy</td>\n",
       "      <td>A tough hockey player is sentenced to serve as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Look Who's Talking Too</td>\n",
       "      <td>In this sequel, a couple deals with the arriva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Drive-Away Dolls</td>\n",
       "      <td>Two friends embark on a road trip seeking a fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Life After Beth</td>\n",
       "      <td>A young man's deceased girlfriend returns from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>40 Days and 40 Nights</td>\n",
       "      <td>After a painful breakup, a man vows to abstain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>The Misfits</td>\n",
       "      <td>A group of modern-day Robin Hoods recruits a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Premature</td>\n",
       "      <td>A high school student relives the same day rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>The Last Days on Mars</td>\n",
       "      <td>Astronauts on Mars discover a deadly organism ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Stolen</td>\n",
       "      <td>A former thief has 12 hours to find $10 millio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>The Haunting</td>\n",
       "      <td>Participants in a sleep study at a haunted man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Be Cool</td>\n",
       "      <td>A mobster enters the music industry, facing ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Turistas</td>\n",
       "      <td>Backpackers stranded in Brazil fall victim to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Teenage Mutant Ninja Turtles III</td>\n",
       "      <td>The turtles travel back in time to 17th-centur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    genre                              name  \\\n",
       "0       1                   Coffee & Kareem   \n",
       "1       2               Unfinished Business   \n",
       "2       3                       Tooth Fairy   \n",
       "3       4            Look Who's Talking Too   \n",
       "4       5                  Drive-Away Dolls   \n",
       "5       6                   Life After Beth   \n",
       "6       7             40 Days and 40 Nights   \n",
       "7       8                       The Misfits   \n",
       "8       9                         Premature   \n",
       "9      10             The Last Days on Mars   \n",
       "10     11                            Stolen   \n",
       "11     12                      The Haunting   \n",
       "12     13                           Be Cool   \n",
       "13     14                          Turistas   \n",
       "14     15  Teenage Mutant Ninja Turtles III   \n",
       "\n",
       "                                          description  \n",
       "0   A 12-year-old boy tries to scare away his moth...  \n",
       "1   A businessman starts his own company and trave...  \n",
       "2   A tough hockey player is sentenced to serve as...  \n",
       "3   In this sequel, a couple deals with the arriva...  \n",
       "4   Two friends embark on a road trip seeking a fr...  \n",
       "5   A young man's deceased girlfriend returns from...  \n",
       "6   After a painful breakup, a man vows to abstain...  \n",
       "7   A group of modern-day Robin Hoods recruits a r...  \n",
       "8   A high school student relives the same day rep...  \n",
       "9   Astronauts on Mars discover a deadly organism ...  \n",
       "10  A former thief has 12 hours to find $10 millio...  \n",
       "11  Participants in a sleep study at a haunted man...  \n",
       "12  A mobster enters the music industry, facing ch...  \n",
       "13  Backpackers stranded in Brazil fall victim to ...  \n",
       "14  The turtles travel back in time to 17th-centur...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2203cb1-7186-4dec-b510-ef6bd8a270cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of     genre                              name  \\\n",
       "0       1                   Coffee & Kareem   \n",
       "1       2               Unfinished Business   \n",
       "2       3                       Tooth Fairy   \n",
       "3       4            Look Who's Talking Too   \n",
       "4       5                  Drive-Away Dolls   \n",
       "5       6                   Life After Beth   \n",
       "6       7             40 Days and 40 Nights   \n",
       "7       8                       The Misfits   \n",
       "8       9                         Premature   \n",
       "9      10             The Last Days on Mars   \n",
       "10     11                            Stolen   \n",
       "11     12                      The Haunting   \n",
       "12     13                           Be Cool   \n",
       "13     14                          Turistas   \n",
       "14     15  Teenage Mutant Ninja Turtles III   \n",
       "\n",
       "                                          description  \n",
       "0   A 12-year-old boy tries to scare away his moth...  \n",
       "1   A businessman starts his own company and trave...  \n",
       "2   A tough hockey player is sentenced to serve as...  \n",
       "3   In this sequel, a couple deals with the arriva...  \n",
       "4   Two friends embark on a road trip seeking a fr...  \n",
       "5   A young man's deceased girlfriend returns from...  \n",
       "6   After a painful breakup, a man vows to abstain...  \n",
       "7   A group of modern-day Robin Hoods recruits a r...  \n",
       "8   A high school student relives the same day rep...  \n",
       "9   Astronauts on Mars discover a deadly organism ...  \n",
       "10  A former thief has 12 hours to find $10 millio...  \n",
       "11  Participants in a sleep study at a haunted man...  \n",
       "12  A mobster enters the music industry, facing ch...  \n",
       "13  Backpackers stranded in Brazil fall victim to ...  \n",
       "14  The turtles travel back in time to 17th-centur...  >"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a38cc308-b49f-4d19-940b-644e06ae081d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in this sequel, a couple deals with the arrival of a new baby, leading to sibling rivalry and humorous situations.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"description\"][3].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8f1f663-d5b9-4b86-8596-dbb3eae9e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def remove_html_tags(description):\n",
    "    clean= re.compile('<.*?>')\n",
    "    return re.sub(clean, '', str(description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f843beb9-7901-41b0-a602-f20811b0d398",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]= df[\"description\"].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76038fef-01d8-473b-acf8-9b97199965fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Coffee &amp; Kareem</td>\n",
       "      <td>A 12-year-old boy tries to scare away his moth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Unfinished Business</td>\n",
       "      <td>A businessman starts his own company and trave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tooth Fairy</td>\n",
       "      <td>A tough hockey player is sentenced to serve as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Look Who's Talking Too</td>\n",
       "      <td>In this sequel, a couple deals with the arriva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Drive-Away Dolls</td>\n",
       "      <td>Two friends embark on a road trip seeking a fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Life After Beth</td>\n",
       "      <td>A young man's deceased girlfriend returns from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>40 Days and 40 Nights</td>\n",
       "      <td>After a painful breakup, a man vows to abstain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>The Misfits</td>\n",
       "      <td>A group of modern-day Robin Hoods recruits a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Premature</td>\n",
       "      <td>A high school student relives the same day rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>The Last Days on Mars</td>\n",
       "      <td>Astronauts on Mars discover a deadly organism ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Stolen</td>\n",
       "      <td>A former thief has 12 hours to find $10 millio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>The Haunting</td>\n",
       "      <td>Participants in a sleep study at a haunted man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Be Cool</td>\n",
       "      <td>A mobster enters the music industry, facing ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Turistas</td>\n",
       "      <td>Backpackers stranded in Brazil fall victim to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Teenage Mutant Ninja Turtles III</td>\n",
       "      <td>The turtles travel back in time to 17th-centur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    genre                              name  \\\n",
       "0       1                   Coffee & Kareem   \n",
       "1       2               Unfinished Business   \n",
       "2       3                       Tooth Fairy   \n",
       "3       4            Look Who's Talking Too   \n",
       "4       5                  Drive-Away Dolls   \n",
       "5       6                   Life After Beth   \n",
       "6       7             40 Days and 40 Nights   \n",
       "7       8                       The Misfits   \n",
       "8       9                         Premature   \n",
       "9      10             The Last Days on Mars   \n",
       "10     11                            Stolen   \n",
       "11     12                      The Haunting   \n",
       "12     13                           Be Cool   \n",
       "13     14                          Turistas   \n",
       "14     15  Teenage Mutant Ninja Turtles III   \n",
       "\n",
       "                                          description  \n",
       "0   A 12-year-old boy tries to scare away his moth...  \n",
       "1   A businessman starts his own company and trave...  \n",
       "2   A tough hockey player is sentenced to serve as...  \n",
       "3   In this sequel, a couple deals with the arriva...  \n",
       "4   Two friends embark on a road trip seeking a fr...  \n",
       "5   A young man's deceased girlfriend returns from...  \n",
       "6   After a painful breakup, a man vows to abstain...  \n",
       "7   A group of modern-day Robin Hoods recruits a r...  \n",
       "8   A high school student relives the same day rep...  \n",
       "9   Astronauts on Mars discover a deadly organism ...  \n",
       "10  A former thief has 12 hours to find $10 millio...  \n",
       "11  Participants in a sleep study at a haunted man...  \n",
       "12  A mobster enters the music industry, facing ch...  \n",
       "13  Backpackers stranded in Brazil fall victim to ...  \n",
       "14  The turtles travel back in time to 17th-centur...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82a84bc3-e821-4629-b033-39f999fbad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punc(description):\n",
    "    excude=string.punctuation\n",
    "    return description.translate(str.maketrans('', '', exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2eaec53c-a48e-4a56-a5f4-e005068e2bbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exclude' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m]=\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdescription\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremove_punc\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4790\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4791\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4796\u001b[39m     **kwargs,\n\u001b[32m   4797\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4799\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4800\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4915\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4916\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4922\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1426\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1427\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1501\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1505\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1506\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1512\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1513\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2972\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mremove_punc\u001b[39m\u001b[34m(description)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mremove_punc\u001b[39m(description):\n\u001b[32m      3\u001b[39m     excude=string.punctuation\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m description.translate(\u001b[38;5;28mstr\u001b[39m.maketrans(\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, \u001b[43mexclude\u001b[49m))\n",
      "\u001b[31mNameError\u001b[39m: name 'exclude' is not defined"
     ]
    }
   ],
   "source": [
    "df[\"description\"]=df[\"description\"].apply(remove_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75540378-8e46-46d0-b739-b3b94935a92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Coffee &amp; Kareem</td>\n",
       "      <td>A 12-year-old boy tries to scare away his moth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Unfinished Business</td>\n",
       "      <td>A businessman starts his own company and trave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tooth Fairy</td>\n",
       "      <td>A tough hockey player is sentenced to serve as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Look Who's Talking Too</td>\n",
       "      <td>In this sequel, a couple deals with the arriva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Drive-Away Dolls</td>\n",
       "      <td>Two friends embark on a road trip seeking a fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Life After Beth</td>\n",
       "      <td>A young man's deceased girlfriend returns from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>40 Days and 40 Nights</td>\n",
       "      <td>After a painful breakup, a man vows to abstain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>The Misfits</td>\n",
       "      <td>A group of modern-day Robin Hoods recruits a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Premature</td>\n",
       "      <td>A high school student relives the same day rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>The Last Days on Mars</td>\n",
       "      <td>Astronauts on Mars discover a deadly organism ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Stolen</td>\n",
       "      <td>A former thief has 12 hours to find $10 millio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>The Haunting</td>\n",
       "      <td>Participants in a sleep study at a haunted man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Be Cool</td>\n",
       "      <td>A mobster enters the music industry, facing ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Turistas</td>\n",
       "      <td>Backpackers stranded in Brazil fall victim to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Teenage Mutant Ninja Turtles III</td>\n",
       "      <td>The turtles travel back in time to 17th-centur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    genre                              name  \\\n",
       "0       1                   Coffee & Kareem   \n",
       "1       2               Unfinished Business   \n",
       "2       3                       Tooth Fairy   \n",
       "3       4            Look Who's Talking Too   \n",
       "4       5                  Drive-Away Dolls   \n",
       "5       6                   Life After Beth   \n",
       "6       7             40 Days and 40 Nights   \n",
       "7       8                       The Misfits   \n",
       "8       9                         Premature   \n",
       "9      10             The Last Days on Mars   \n",
       "10     11                            Stolen   \n",
       "11     12                      The Haunting   \n",
       "12     13                           Be Cool   \n",
       "13     14                          Turistas   \n",
       "14     15  Teenage Mutant Ninja Turtles III   \n",
       "\n",
       "                                          description  \n",
       "0   A 12-year-old boy tries to scare away his moth...  \n",
       "1   A businessman starts his own company and trave...  \n",
       "2   A tough hockey player is sentenced to serve as...  \n",
       "3   In this sequel, a couple deals with the arriva...  \n",
       "4   Two friends embark on a road trip seeking a fr...  \n",
       "5   A young man's deceased girlfriend returns from...  \n",
       "6   After a painful breakup, a man vows to abstain...  \n",
       "7   A group of modern-day Robin Hoods recruits a r...  \n",
       "8   A high school student relives the same day rep...  \n",
       "9   Astronauts on Mars discover a deadly organism ...  \n",
       "10  A former thief has 12 hours to find $10 millio...  \n",
       "11  Participants in a sleep study at a haunted man...  \n",
       "12  A mobster enters the music industry, facing ch...  \n",
       "13  Backpackers stranded in Brazil fall victim to ...  \n",
       "14  The turtles travel back in time to 17th-centur...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3d79760-efbc-4bd3-9154-055c13bf681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12efe9a3-e840-4f95-bac4-d91d3e29194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].apply(lambda x: str(TextBlob(str(x)).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61555d33-dfc6-4dc5-9f67-b8937e28ce37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Coffee &amp; Kareem</td>\n",
       "      <td>A 12-year-old boy tries to scare away his moth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Unfinished Business</td>\n",
       "      <td>A businessman starts his own company and trave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tooth Fairy</td>\n",
       "      <td>A tough hockey player is sentenced to serve as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Look Who's Talking Too</td>\n",
       "      <td>In this sequel, a couple deals with the arriva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Drive-Away Dolls</td>\n",
       "      <td>Two friends embark on a road trip seeking a fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Life After Beth</td>\n",
       "      <td>A young man's deceased girlfriend returns from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>40 Days and 40 Nights</td>\n",
       "      <td>After a painful breakup, a man vows to abstain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>The Misfits</td>\n",
       "      <td>A group of modern-day Robin Goods recruits a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Premature</td>\n",
       "      <td>A high school student relieves the same day re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>The Last Days on Mars</td>\n",
       "      <td>Astronauts on Wars discover a deadly organism ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Stolen</td>\n",
       "      <td>A former thief has 12 hours to find $10 millio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>The Haunting</td>\n",
       "      <td>Participants in a sleep study at a haunted man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Be Cool</td>\n",
       "      <td>A monster enters the music industry, facing ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Turistas</td>\n",
       "      <td>Backpackers strange in Brazil fall victim to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Teenage Mutant Ninja Turtles III</td>\n",
       "      <td>The turtle travel back in time to with-century...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    genre                              name  \\\n",
       "0       1                   Coffee & Kareem   \n",
       "1       2               Unfinished Business   \n",
       "2       3                       Tooth Fairy   \n",
       "3       4            Look Who's Talking Too   \n",
       "4       5                  Drive-Away Dolls   \n",
       "5       6                   Life After Beth   \n",
       "6       7             40 Days and 40 Nights   \n",
       "7       8                       The Misfits   \n",
       "8       9                         Premature   \n",
       "9      10             The Last Days on Mars   \n",
       "10     11                            Stolen   \n",
       "11     12                      The Haunting   \n",
       "12     13                           Be Cool   \n",
       "13     14                          Turistas   \n",
       "14     15  Teenage Mutant Ninja Turtles III   \n",
       "\n",
       "                                          description  \n",
       "0   A 12-year-old boy tries to scare away his moth...  \n",
       "1   A businessman starts his own company and trave...  \n",
       "2   A tough hockey player is sentenced to serve as...  \n",
       "3   In this sequel, a couple deals with the arriva...  \n",
       "4   Two friends embark on a road trip seeking a fr...  \n",
       "5   A young man's deceased girlfriend returns from...  \n",
       "6   After a painful breakup, a man vows to abstain...  \n",
       "7   A group of modern-day Robin Goods recruits a r...  \n",
       "8   A high school student relieves the same day re...  \n",
       "9   Astronauts on Wars discover a deadly organism ...  \n",
       "10  A former thief has 12 hours to find $10 millio...  \n",
       "11  Participants in a sleep study at a haunted man...  \n",
       "12  A monster enters the music industry, facing ch...  \n",
       "13  Backpackers strange in Brazil fall victim to a...  \n",
       "14  The turtle travel back in time to with-century...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d1c60ff-84aa-4166-a8bd-6783ed773eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in e:\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in e:\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in e:\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in e:\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in e:\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b0d1acf-41a3-41db-898a-9183f93f1166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "705ffca0-aa07-455d-a0a3-4b5bfa05306a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6170a813-eb3c-4d92-9fbf-419e2beb9cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'m', 'do', 'while', 'itself', 'during', 'from', \"shan't\", 'that', 'where', \"we're\", 'into', \"didn't\", 'below', \"i'll\", 'me', \"wouldn't\", 'few', \"he'd\", 'needn', 'only', 'weren', 'once', \"i've\", 'to', 'has', 'wouldn', \"you'll\", 'any', 'now', 'nor', \"they'd\", 'against', 'under', 't', 'mustn', 'after', 'hers', 'our', 'the', 'then', 'his', 'hadn', 'having', \"shouldn't\", 'so', 'above', \"you've\", 'such', 'ourselves', 'on', \"it's\", 'whom', 'myself', 'is', 'off', 'aren', 'can', \"you'd\", 'we', \"needn't\", \"we'll\", \"haven't\", 'until', 'shouldn', 'ours', 'than', 'at', 'not', 'didn', \"she's\", 'same', 'isn', \"won't\", 'or', \"wasn't\", 'with', \"they've\", 'won', \"doesn't\", 'are', 'about', 'most', 'further', 'out', 'herself', 'have', 'be', 'just', 'o', 'in', 'himself', 'how', 'will', 'those', 'him', 'themselves', 'this', 's', 've', 'some', 'up', 'and', 'they', 'ma', 'should', 'as', 'but', 'did', \"isn't\", 'ain', \"they'll\", 'she', \"you're\", 'their', 'hasn', 're', \"i'd\", 'more', \"weren't\", \"he's\", 'because', 'who', 'why', 'over', 'your', 'through', 'yourselves', 'for', 'its', 'been', 'am', 'y', 'a', \"we've\", 'what', 'these', 'them', \"aren't\", \"couldn't\", \"don't\", \"mightn't\", 'it', 'other', 'when', 'an', 'theirs', \"that'll\", 'd', 'there', 'by', 'had', 'her', 'doesn', 'does', 'of', 'he', \"should've\", 'no', 'here', \"she'd\", 'mightn', 'yourself', \"they're\", 'yours', 'if', 'all', 'between', 'down', \"mustn't\", 'i', 'doing', 'were', \"i'm\", 'being', 'wasn', \"hasn't\", 'shan', 'my', 'very', \"we'd\", \"it'll\", 'which', \"she'll\", \"it'd\", 'you', 'don', 'too', 'again', 'each', \"he'll\", 'was', 'll', 'couldn', \"hadn't\", 'both', 'own', 'before', 'haven'}\n"
     ]
    }
   ],
   "source": [
    "stop_words= set(stopwords.words('english'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbf19e8f-e848-4bcc-bce9-5c6e63c46ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eda57c8e-9e26-4caf-9bab-4a026fb08515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    words = str(text).split()\n",
    "    filtered = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf41159f-6f6c-4fab-83ac-c6dee41d22ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"] = df[\"description\"].apply(remove_stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f121fbf2-0aa2-4d57-9c53-e6d850016e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    words = str(text).split()\n",
    "    filtered = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a1a983f-eb19-4a49-afd8-8adf454de5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"] = df[\"description\"].apply(remove_stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63a9d33e-773b-4d81-88c2-901a524dd6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Coffee &amp; Kareem</td>\n",
       "      <td>12-year-old boy tries scare away mother's new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Unfinished Business</td>\n",
       "      <td>businessman starts company travels Europe asso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tooth Fairy</td>\n",
       "      <td>tough hockey player sentenced serve real-life ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Look Who's Talking Too</td>\n",
       "      <td>sequel, couple deals arrival new baby, leading...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Drive-Away Dolls</td>\n",
       "      <td>Two friends embark road trip seeking fresh sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Life After Beth</td>\n",
       "      <td>young man's deceased girlfriend returns dead, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>40 Days and 40 Nights</td>\n",
       "      <td>painful breakup, man vows abstain sexual activ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>The Misfits</td>\n",
       "      <td>group modern-day Robin Goods recruits renowned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Premature</td>\n",
       "      <td>high school student relieves day repeatedly, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>The Last Days on Mars</td>\n",
       "      <td>Astronauts Wars discover deadly organism turns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Stolen</td>\n",
       "      <td>former thief 12 hours find $10 million rescue ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>The Haunting</td>\n",
       "      <td>Participants sleep study haunted mansion exper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Be Cool</td>\n",
       "      <td>monster enters music industry, facing challeng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Turistas</td>\n",
       "      <td>Backpackers strange Brazil fall victim siniste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Teenage Mutant Ninja Turtles III</td>\n",
       "      <td>turtle travel back time with-century Japan res...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    genre                              name  \\\n",
       "0       1                   Coffee & Kareem   \n",
       "1       2               Unfinished Business   \n",
       "2       3                       Tooth Fairy   \n",
       "3       4            Look Who's Talking Too   \n",
       "4       5                  Drive-Away Dolls   \n",
       "5       6                   Life After Beth   \n",
       "6       7             40 Days and 40 Nights   \n",
       "7       8                       The Misfits   \n",
       "8       9                         Premature   \n",
       "9      10             The Last Days on Mars   \n",
       "10     11                            Stolen   \n",
       "11     12                      The Haunting   \n",
       "12     13                           Be Cool   \n",
       "13     14                          Turistas   \n",
       "14     15  Teenage Mutant Ninja Turtles III   \n",
       "\n",
       "                                          description  \n",
       "0   12-year-old boy tries scare away mother's new ...  \n",
       "1   businessman starts company travels Europe asso...  \n",
       "2   tough hockey player sentenced serve real-life ...  \n",
       "3   sequel, couple deals arrival new baby, leading...  \n",
       "4   Two friends embark road trip seeking fresh sta...  \n",
       "5   young man's deceased girlfriend returns dead, ...  \n",
       "6   painful breakup, man vows abstain sexual activ...  \n",
       "7   group modern-day Robin Goods recruits renowned...  \n",
       "8   high school student relieves day repeatedly, t...  \n",
       "9   Astronauts Wars discover deadly organism turns...  \n",
       "10  former thief 12 hours find $10 million rescue ...  \n",
       "11  Participants sleep study haunted mansion exper...  \n",
       "12  monster enters music industry, facing challeng...  \n",
       "13  Backpackers strange Brazil fall victim siniste...  \n",
       "14  turtle travel back time with-century Japan res...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d90db14d-c133-4a13-b25a-e1333645053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f11cc92c-0cc1-4e89-872b-4723a34dd61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "870b3cb2-9f25-41d1-aa98-842dc815808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(description):\n",
    "   return \" \".join([ps.stem(word) for word in description.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0e62142-082c-4287-ba2a-e6a5483ad9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].apply (stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43034740-8baf-4f8c-b928-ff09169fb504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Coffee &amp; Kareem</td>\n",
       "      <td>12-year-old boy tri scare away mother' new boy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Unfinished Business</td>\n",
       "      <td>businessman start compani travel europ associ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tooth Fairy</td>\n",
       "      <td>tough hockey player sentenc serv real-lif toot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Look Who's Talking Too</td>\n",
       "      <td>sequel, coupl deal arriv new baby, lead sit ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Drive-Away Dolls</td>\n",
       "      <td>two friend embark road trip seek fresh start b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Life After Beth</td>\n",
       "      <td>young man' deceas girlfriend return dead, lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>40 Days and 40 Nights</td>\n",
       "      <td>pain breakup, man vow abstain sexual activ wen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>The Misfits</td>\n",
       "      <td>group modern-day robin good recruit renown thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Premature</td>\n",
       "      <td>high school student reliev day repeatedly, tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>The Last Days on Mars</td>\n",
       "      <td>astronaut war discov deadli organ turn combine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Stolen</td>\n",
       "      <td>former thief 12 hour find $10 million rescu ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>The Haunting</td>\n",
       "      <td>particip sleep studi haunt mansion experi terr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Be Cool</td>\n",
       "      <td>monster enter music industry, face challeng tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Turistas</td>\n",
       "      <td>backpack strang brazil fall victim sinist orga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Teenage Mutant Ninja Turtles III</td>\n",
       "      <td>turtl travel back time with-centuri japan resc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    genre                              name  \\\n",
       "0       1                   Coffee & Kareem   \n",
       "1       2               Unfinished Business   \n",
       "2       3                       Tooth Fairy   \n",
       "3       4            Look Who's Talking Too   \n",
       "4       5                  Drive-Away Dolls   \n",
       "5       6                   Life After Beth   \n",
       "6       7             40 Days and 40 Nights   \n",
       "7       8                       The Misfits   \n",
       "8       9                         Premature   \n",
       "9      10             The Last Days on Mars   \n",
       "10     11                            Stolen   \n",
       "11     12                      The Haunting   \n",
       "12     13                           Be Cool   \n",
       "13     14                          Turistas   \n",
       "14     15  Teenage Mutant Ninja Turtles III   \n",
       "\n",
       "                                          description  \n",
       "0   12-year-old boy tri scare away mother' new boy...  \n",
       "1   businessman start compani travel europ associ ...  \n",
       "2   tough hockey player sentenc serv real-lif toot...  \n",
       "3   sequel, coupl deal arriv new baby, lead sit ri...  \n",
       "4   two friend embark road trip seek fresh start b...  \n",
       "5   young man' deceas girlfriend return dead, lead...  \n",
       "6   pain breakup, man vow abstain sexual activ wen...  \n",
       "7   group modern-day robin good recruit renown thi...  \n",
       "8   high school student reliev day repeatedly, tri...  \n",
       "9   astronaut war discov deadli organ turn combine...  \n",
       "10  former thief 12 hour find $10 million rescu ki...  \n",
       "11  particip sleep studi haunt mansion experi terr...  \n",
       "12  monster enter music industry, face challeng tr...  \n",
       "13  backpack strang brazil fall victim sinist orga...  \n",
       "14  turtl travel back time with-centuri japan resc...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe78983f-dd3c-4b1e-9c9e-30a5e7012df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80a25b2c-575d-44b2-b8c4-2029a44c2a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from  nltk.corpus import wordnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "39c26e3c-6d65-4c49-b8be-a8f3815b08d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e76b262d-c015-4934-b2e4-f66eb29ebc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c6ac37f-7239-4439-a316-a18db24ae315",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer= WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "91505d34-6193-415a-9d48-13c9c27bb3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6aeb1d45-fc56-4c62-b10c-02f361e1a1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Error downloading 'omw-1.4' from\n",
      "[nltk_data]     <https://raw.githubusercontent.com/nltk/nltk_data/gh-\n",
      "[nltk_data]     pages/packages/corpora/omw-1.4.zip>:   <urlopen error\n",
      "[nltk_data]     [WinError 10054] An existing connection was forcibly\n",
      "[nltk_data]     closed by the remote host>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c026b983-eed7-4c71-aa47-04b07888f510",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Administrator/nltk_data'\n    - 'E:nltk_data'\n    - 'E:share\\\\nltk_data'\n    - 'E:lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Administrator\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      1\u001b[39m description = [\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mA 12-year-old boy tries to scare away his mother\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms new boyfriend, a police officer, but his plan backfires, exposing them to a criminal network.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mA businessman starts his own company and travels to Europe with his associates to close an important deal, facing unexpected challenges.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mA group of modern-day Robin Hoods recruits a renowned thief to help them pull off a heist targeting a corrupt businessman.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m ]\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m description:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     words = \u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     lemmatized = [lemmatizer.lemmatize(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mline\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m-> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(lemmatized)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:142\u001b[39m, in \u001b[36mword_tokenize\u001b[39m\u001b[34m(text, language, preserve_line)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mword_tokenize\u001b[39m(text, language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m, preserve_line=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    128\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[33;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[33;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m \u001b[33;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     sentences = [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    144\u001b[39m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer.tokenize(sent)\n\u001b[32m    145\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:119\u001b[39m, in \u001b[36msent_tokenize\u001b[39m\u001b[34m(text, language)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msent_tokenize\u001b[39m(text, language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    110\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[33;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[33;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    117\u001b[39m \u001b[33;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     tokenizer = \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer.tokenize(text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:105\u001b[39m, in \u001b[36m_get_punkt_tokenizer\u001b[39m\u001b[34m(language)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;129m@functools\u001b[39m.lru_cache\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_punkt_tokenizer\u001b[39m(language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     98\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[33;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03m    a lru cache for performance.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m \u001b[33;03m    :type language: str\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1744\u001b[39m, in \u001b[36mPunktTokenizer.__init__\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1743\u001b[39m     PunktSentenceTokenizer.\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1744\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1749\u001b[39m, in \u001b[36mPunktTokenizer.load_lang\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1746\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1747\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[32m-> \u001b[39m\u001b[32m1749\u001b[39m     lang_dir = \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1750\u001b[39m     \u001b[38;5;28mself\u001b[39m._params = load_punkt_params(lang_dir)\n\u001b[32m   1751\u001b[39m     \u001b[38;5;28mself\u001b[39m._lang = lang\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\nltk\\data.py:579\u001b[39m, in \u001b[36mfind\u001b[39m\u001b[34m(resource_name, paths)\u001b[39m\n\u001b[32m    577\u001b[39m sep = \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m\n\u001b[32m    578\u001b[39m resource_not_found = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[31mLookupError\u001b[39m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Administrator/nltk_data'\n    - 'E:nltk_data'\n    - 'E:share\\\\nltk_data'\n    - 'E:lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Administrator\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "description = [\n",
    "    \"A 12-year-old boy tries to scare away his mother's new boyfriend, a police officer, but his plan backfires, exposing them to a criminal network.\",\n",
    "    \"A businessman starts his own company and travels to Europe with his associates to close an important deal, facing unexpected challenges.\",\n",
    "    \"A tough hockey player is sentenced to serve as a real-life tooth fairy for a week after discouraging a child's dreams.\",\n",
    "    \"In this sequel, a couple deals with the arrival of a new baby, leading to sibling rivalry and humorous situations.\",\n",
    "    \"Two friends embark on a road trip seeking a fresh start but become entangled in a criminal scheme.\",\n",
    "    \"A young man's deceased girlfriend returns from the dead, leading to unexpected and bizarre consequences.\",\n",
    "    \"After a painful breakup, a man vows to abstain from any sexual activity for Lent, but complications arise when he meets someone new.\",\n",
    "    \"A group of modern-day Robin Hoods recruits a renowned thief to help them pull off a heist targeting a corrupt businessman.\"\n",
    "]\n",
    "\n",
    "for line in description:\n",
    "    words = word_tokenize(line)\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in words]\n",
    "    print(f\"{line} \\n-> {' '.join(lemmatized)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "51e441ae-de57-4894-a57e-b263ceda18b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def tokenize_text(description):\n",
    "    tokens=re.findall(r'\\b\\w+\\b', description)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "458f375b-b87e-41b3-8210-5c14bc74156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c5357d39-d957-4287-aea8-36e56ea9c290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Coffee &amp; Kareem</td>\n",
       "      <td>[12, year, old, boy, tri, scare, away, mother,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Unfinished Business</td>\n",
       "      <td>[businessman, start, compani, travel, europ, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tooth Fairy</td>\n",
       "      <td>[tough, hockey, player, sentenc, serv, real, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Look Who's Talking Too</td>\n",
       "      <td>[sequel, coupl, deal, arriv, new, baby, lead, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Drive-Away Dolls</td>\n",
       "      <td>[two, friend, embark, road, trip, seek, fresh,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Life After Beth</td>\n",
       "      <td>[young, man, deceas, girlfriend, return, dead,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>40 Days and 40 Nights</td>\n",
       "      <td>[pain, breakup, man, vow, abstain, sexual, act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>The Misfits</td>\n",
       "      <td>[group, modern, day, robin, good, recruit, ren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Premature</td>\n",
       "      <td>[high, school, student, reliev, day, repeatedl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>The Last Days on Mars</td>\n",
       "      <td>[astronaut, war, discov, deadli, organ, turn, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Stolen</td>\n",
       "      <td>[former, thief, 12, hour, find, 10, million, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>The Haunting</td>\n",
       "      <td>[particip, sleep, studi, haunt, mansion, exper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Be Cool</td>\n",
       "      <td>[monster, enter, music, industry, face, challe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Turistas</td>\n",
       "      <td>[backpack, strang, brazil, fall, victim, sinis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Teenage Mutant Ninja Turtles III</td>\n",
       "      <td>[turtl, travel, back, time, with, centuri, jap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    genre                              name  \\\n",
       "0       1                   Coffee & Kareem   \n",
       "1       2               Unfinished Business   \n",
       "2       3                       Tooth Fairy   \n",
       "3       4            Look Who's Talking Too   \n",
       "4       5                  Drive-Away Dolls   \n",
       "5       6                   Life After Beth   \n",
       "6       7             40 Days and 40 Nights   \n",
       "7       8                       The Misfits   \n",
       "8       9                         Premature   \n",
       "9      10             The Last Days on Mars   \n",
       "10     11                            Stolen   \n",
       "11     12                      The Haunting   \n",
       "12     13                           Be Cool   \n",
       "13     14                          Turistas   \n",
       "14     15  Teenage Mutant Ninja Turtles III   \n",
       "\n",
       "                                          description  \n",
       "0   [12, year, old, boy, tri, scare, away, mother,...  \n",
       "1   [businessman, start, compani, travel, europ, a...  \n",
       "2   [tough, hockey, player, sentenc, serv, real, l...  \n",
       "3   [sequel, coupl, deal, arriv, new, baby, lead, ...  \n",
       "4   [two, friend, embark, road, trip, seek, fresh,...  \n",
       "5   [young, man, deceas, girlfriend, return, dead,...  \n",
       "6   [pain, breakup, man, vow, abstain, sexual, act...  \n",
       "7   [group, modern, day, robin, good, recruit, ren...  \n",
       "8   [high, school, student, reliev, day, repeatedl...  \n",
       "9   [astronaut, war, discov, deadli, organ, turn, ...  \n",
       "10  [former, thief, 12, hour, find, 10, million, r...  \n",
       "11  [particip, sleep, studi, haunt, mansion, exper...  \n",
       "12  [monster, enter, music, industry, face, challe...  \n",
       "13  [backpack, strang, brazil, fall, victim, sinis...  \n",
       "14  [turtl, travel, back, time, with, centuri, jap...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1f8d58e3-09fb-4d03-9d8a-ab1b405864d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "232eebea-4eec-48d7-b1fc-9db06540c59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "139437bd-2b7b-4a5c-b80b-d81d899b5139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Error downloading 'maxent_ne_chunker' from\n",
      "[nltk_data]     <https://raw.githubusercontent.com/nltk/nltk_data/gh-\n",
      "[nltk_data]     pages/packages/chunkers/maxent_ne_chunker.zip>:\n",
      "[nltk_data]     <urlopen error [WinError 10054] An existing connection\n",
      "[nltk_data]     was forcibly closed by the remote host>\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a4472c8b-0856-4cc2-8d98-9058820572db",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'A 12-year-old boy tries to scare away his mother's new boyfriend, a police officer, but his plan backfires, exposing them to a criminal network.' is not a valid function for 'Series' object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[88]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      1\u001b[39m description = [\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mA 12-year-old boy tries to scare away his mother\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms new boyfriend, a police officer, but his plan backfires, exposing them to a criminal network.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mA businessman starts his own company and travels to Europe with his associates to close an important deal, facing unexpected challenges.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mA group of modern-day Robin Hoods recruits a renowned thief to help them pull off a heist targeting a corrupt businessman.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m]=\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdescription\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4790\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4791\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4796\u001b[39m     **kwargs,\n\u001b[32m   4797\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4799\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4800\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4915\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4916\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4922\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\pandas\\core\\apply.py:1417\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1415\u001b[39m \u001b[38;5;66;03m# dispatch to handle list-like or dict-like\u001b[39;00m\n\u001b[32m   1416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(\u001b[38;5;28mself\u001b[39m.func):\n\u001b[32m-> \u001b[39m\u001b[32m1417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_list_or_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.func, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   1420\u001b[39m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[32m   1421\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_str()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\pandas\\core\\apply.py:630\u001b[39m, in \u001b[36mApply.apply_list_or_dict_like\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    628\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.agg_or_apply_dict_like(op_name=\u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magg_or_apply_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapply\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    632\u001b[39m result = reconstruct_and_relabel_result(result, func, **kwargs)\n\u001b[32m    634\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\pandas\\core\\apply.py:744\u001b[39m, in \u001b[36mNDFrameApply.agg_or_apply_list_like\u001b[39m\u001b[34m(self, op_name)\u001b[39m\n\u001b[32m    741\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33maxis\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0\u001b[39m) == \u001b[32m1\u001b[39m:\n\u001b[32m    742\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33maxis other than 0 is not supported\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m744\u001b[39m keys, results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    745\u001b[39m result = \u001b[38;5;28mself\u001b[39m.wrap_results_list_like(keys, results)\n\u001b[32m    746\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\pandas\\core\\apply.py:369\u001b[39m, in \u001b[36mApply.compute_list_like\u001b[39m\u001b[34m(self, op_name, selected_obj, kwargs)\u001b[39m\n\u001b[32m    363\u001b[39m colg = obj._gotitem(selected_obj.name, ndim=\u001b[32m1\u001b[39m, subset=selected_obj)\n\u001b[32m    364\u001b[39m args = (\n\u001b[32m    365\u001b[39m     [\u001b[38;5;28mself\u001b[39m.axis, *\u001b[38;5;28mself\u001b[39m.args]\n\u001b[32m    366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m include_axis(op_name, colg)\n\u001b[32m    367\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args\n\u001b[32m    368\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m new_res = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    370\u001b[39m results.append(new_res)\n\u001b[32m    372\u001b[39m \u001b[38;5;66;03m# make sure we find a good name\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4790\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4791\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4796\u001b[39m     **kwargs,\n\u001b[32m   4797\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4799\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4800\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4915\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4916\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4922\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\pandas\\core\\apply.py:1421\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_list_or_dict_like()\n\u001b[32m   1419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.func, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   1420\u001b[39m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1421\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1423\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.by_row == \u001b[33m\"\u001b[39m\u001b[33m_compat\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\pandas\\core\\apply.py:603\u001b[39m, in \u001b[36mApply.apply_str\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    601\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    602\u001b[39m             \u001b[38;5;28mself\u001b[39m.kwargs[\u001b[33m\"\u001b[39m\u001b[33maxis\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.axis\n\u001b[32m--> \u001b[39m\u001b[32m603\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\pandas\\core\\apply.py:706\u001b[39m, in \u001b[36mApply._apply_str\u001b[39m\u001b[34m(self, obj, func, *args, **kwargs)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    705\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is not a valid function for \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n",
      "\u001b[31mAttributeError\u001b[39m: 'A 12-year-old boy tries to scare away his mother's new boyfriend, a police officer, but his plan backfires, exposing them to a criminal network.' is not a valid function for 'Series' object"
     ]
    }
   ],
   "source": [
    "description = [\n",
    "    \"A 12-year-old boy tries to scare away his mother's new boyfriend, a police officer, but his plan backfires, exposing them to a criminal network.\",\n",
    "    \"A businessman starts his own company and travels to Europe with his associates to close an important deal, facing unexpected challenges.\",\n",
    "    \"A tough hockey player is sentenced to serve as a real-life tooth fairy for a week after discouraging a child's dreams.\",\n",
    "    \"In this sequel, a couple deals with the arrival of a new baby, leading to sibling rivalry and humorous situations.\",\n",
    "    \"Two friends embark on a road trip seeking a fresh start but become entangled in a criminal scheme.\",\n",
    "    \"A young man's deceased girlfriend returns from the dead, leading to unexpected and bizarre consequences.\",\n",
    "    \"After a painful breakup, a man vows to abstain from any sexual activity for Lent, but complications arise when he meets someone new.\",\n",
    "    \"A group of modern-day Robin Hoods recruits a renowned thief to help them pull off a heist targeting a corrupt businessman.\"\n",
    "]\n",
    "df[\"description\"]=df[\"description\"].apply(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "65ff14c1-146d-4eeb-bba4-393af3a2ddff",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Administrator/nltk_data'\n    - 'E:nltk_data'\n    - 'E:share\\\\nltk_data'\n    - 'E:lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Administrator\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      1\u001b[39m description = [\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mA 12-year-old boy tries to scare away his mother\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms new boyfriend, a police officer, but his plan backfires, exposing them to a criminal network.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mA businessman starts his own company and travels to Europe with his associates to close an important deal, facing unexpected challenges.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mA group of modern-day Robin Hoods recruits a renowned thief to help them pull off a heist targeting a corrupt businessman.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m ]\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m description:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     tokens= \u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:142\u001b[39m, in \u001b[36mword_tokenize\u001b[39m\u001b[34m(text, language, preserve_line)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mword_tokenize\u001b[39m(text, language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m, preserve_line=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    128\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[33;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[33;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m \u001b[33;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     sentences = [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    144\u001b[39m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer.tokenize(sent)\n\u001b[32m    145\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:119\u001b[39m, in \u001b[36msent_tokenize\u001b[39m\u001b[34m(text, language)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msent_tokenize\u001b[39m(text, language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    110\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[33;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[33;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    117\u001b[39m \u001b[33;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     tokenizer = \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer.tokenize(text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:105\u001b[39m, in \u001b[36m_get_punkt_tokenizer\u001b[39m\u001b[34m(language)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;129m@functools\u001b[39m.lru_cache\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_punkt_tokenizer\u001b[39m(language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     98\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[33;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03m    a lru cache for performance.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m \u001b[33;03m    :type language: str\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1744\u001b[39m, in \u001b[36mPunktTokenizer.__init__\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1743\u001b[39m     PunktSentenceTokenizer.\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1744\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1749\u001b[39m, in \u001b[36mPunktTokenizer.load_lang\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1746\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1747\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[32m-> \u001b[39m\u001b[32m1749\u001b[39m     lang_dir = \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1750\u001b[39m     \u001b[38;5;28mself\u001b[39m._params = load_punkt_params(lang_dir)\n\u001b[32m   1751\u001b[39m     \u001b[38;5;28mself\u001b[39m._lang = lang\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\nltk\\data.py:579\u001b[39m, in \u001b[36mfind\u001b[39m\u001b[34m(resource_name, paths)\u001b[39m\n\u001b[32m    577\u001b[39m sep = \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m\n\u001b[32m    578\u001b[39m resource_not_found = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[31mLookupError\u001b[39m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Administrator/nltk_data'\n    - 'E:nltk_data'\n    - 'E:share\\\\nltk_data'\n    - 'E:lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Administrator\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "description = [\n",
    "    \"A 12-year-old boy tries to scare away his mother's new boyfriend, a police officer, but his plan backfires, exposing them to a criminal network.\",\n",
    "    \"A businessman starts his own company and travels to Europe with his associates to close an important deal, facing unexpected challenges.\",\n",
    "    \"A tough hockey player is sentenced to serve as a real-life tooth fairy for a week after discouraging a child's dreams.\",\n",
    "    \"In this sequel, a couple deals with the arrival of a new baby, leading to sibling rivalry and humorous situations.\",\n",
    "    \"Two friends embark on a road trip seeking a fresh start but become entangled in a criminal scheme.\",\n",
    "    \"A young man's deceased girlfriend returns from the dead, leading to unexpected and bizarre consequences.\",\n",
    "    \"After a painful breakup, a man vows to abstain from any sexual activity for Lent, but complications arise when he meets someone new.\",\n",
    "    \"A group of modern-day Robin Hoods recruits a renowned thief to help them pull off a heist targeting a corrupt businessman.\"\n",
    "]\n",
    "for line in description:\n",
    "    tokens= word_tokenize(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ddc91757-96ac-4c81-8ffe-1e9e4a88f708",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[87]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m]= df[\u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m].apply(\u001b[43mtokens\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'tokens' is not defined"
     ]
    }
   ],
   "source": [
    "df[\"description\"]= df[\"description\"].apply(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3f9763fb-bdac-4070-9776-570e7550e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "description = [\n",
    "    \"A 12-year-old boy tries to scare away his mother's new boyfriend, a police officer, but his plan backfires, exposing them to a criminal network.\",\n",
    "    \"A businessman starts his own company and travels to Europe with his associates to close an important deal, facing unexpected challenges.\",\n",
    "    \"A tough hockey player is sentenced to serve as a real-life tooth fairy for a week after discouraging a child's dreams.\",\n",
    "    \"In this sequel, a couple deals with the arrival of a new baby, leading to sibling rivalry and humorous situations.\",\n",
    "    \"Two friends embark on a road trip seeking a fresh start but become entangled in a criminal scheme.\",\n",
    "    \"A young man's deceased girlfriend returns from the dead, leading to unexpected and bizarre consequences.\",\n",
    "    \"After a painful breakup, a man vows to abstain from any sexual activity for Lent, but complications arise when he meets someone new.\",\n",
    "    \"A group of modern-day Robin Hoods recruits a renowned thief to help them pull off a heist targeting a corrupt businessman.\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame({'description': description})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "42eef11e-4b23-44a9-835b-505cb5d80ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10054] An\n",
      "[nltk_data]     existing connection was forcibly closed by the remote\n",
      "[nltk_data]     host>\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Administrator/nltk_data'\n    - 'E:nltk_data'\n    - 'E:share\\\\nltk_data'\n    - 'E:lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Administrator\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m nltk.download(\u001b[33m'\u001b[39m\u001b[33mpunkt\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# First-time download\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Tokenize each description\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mtokens\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdescription\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_tokenize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4790\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4791\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4796\u001b[39m     **kwargs,\n\u001b[32m   4797\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4799\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4800\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4915\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4916\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4922\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1426\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1427\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1501\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1505\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1506\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1512\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1513\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2972\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:142\u001b[39m, in \u001b[36mword_tokenize\u001b[39m\u001b[34m(text, language, preserve_line)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mword_tokenize\u001b[39m(text, language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m, preserve_line=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    128\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[33;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[33;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m \u001b[33;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     sentences = [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    144\u001b[39m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer.tokenize(sent)\n\u001b[32m    145\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:119\u001b[39m, in \u001b[36msent_tokenize\u001b[39m\u001b[34m(text, language)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msent_tokenize\u001b[39m(text, language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    110\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[33;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[33;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    117\u001b[39m \u001b[33;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     tokenizer = \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer.tokenize(text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:105\u001b[39m, in \u001b[36m_get_punkt_tokenizer\u001b[39m\u001b[34m(language)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;129m@functools\u001b[39m.lru_cache\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_punkt_tokenizer\u001b[39m(language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     98\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[33;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03m    a lru cache for performance.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m \u001b[33;03m    :type language: str\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1744\u001b[39m, in \u001b[36mPunktTokenizer.__init__\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1743\u001b[39m     PunktSentenceTokenizer.\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1744\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1749\u001b[39m, in \u001b[36mPunktTokenizer.load_lang\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1746\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1747\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[32m-> \u001b[39m\u001b[32m1749\u001b[39m     lang_dir = \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1750\u001b[39m     \u001b[38;5;28mself\u001b[39m._params = load_punkt_params(lang_dir)\n\u001b[32m   1751\u001b[39m     \u001b[38;5;28mself\u001b[39m._lang = lang\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Lib\\site-packages\\nltk\\data.py:579\u001b[39m, in \u001b[36mfind\u001b[39m\u001b[34m(resource_name, paths)\u001b[39m\n\u001b[32m    577\u001b[39m sep = \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m\n\u001b[32m    578\u001b[39m resource_not_found = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[31mLookupError\u001b[39m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Administrator/nltk_data'\n    - 'E:nltk_data'\n    - 'E:share\\\\nltk_data'\n    - 'E:lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Administrator\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')  # First-time download\n",
    "\n",
    "# Tokenize each description\n",
    "df[\"tokens\"] = df[\"description\"].apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a0a1fb4d-7e0f-4251-aef7-143269ca0e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         description\n",
      "0  A 12-year-old boy tries to scare away his moth...\n",
      "1  A businessman starts his own company and trave...\n"
     ]
    }
   ],
   "source": [
    "print(df.head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7215150-1aeb-44b7-a71d-bec6570ddf81",
   "metadata": {},
   "source": [
    "SPACY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "13a4bdc5-b90c-4c99-8865-801d4c758878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Using cached spacy-3.8.2.tar.gz (1.3 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  pip subprocess to install build dependencies did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [67 lines of output]\n",
      "  Ignoring numpy: markers 'python_version < \"3.9\"' don't match your environment\n",
      "  Collecting setuptools\n",
      "    Using cached setuptools-80.2.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Collecting cython<3.0,>=0.25\n",
      "    Using cached Cython-0.29.37-py2.py3-none-any.whl.metadata (3.1 kB)\n",
      "  Collecting cymem<2.1.0,>=2.0.2\n",
      "    Using cached cymem-2.0.11-cp313-cp313-win_amd64.whl.metadata (8.8 kB)\n",
      "  Collecting preshed<3.1.0,>=3.0.2\n",
      "    Using cached preshed-3.0.9.tar.gz (14 kB)\n",
      "    Installing build dependencies: started\n",
      "    Installing build dependencies: finished with status 'done'\n",
      "    Getting requirements to build wheel: started\n",
      "    Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing metadata (pyproject.toml): started\n",
      "    Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Collecting murmurhash<1.1.0,>=0.28.0\n",
      "    Using cached murmurhash-1.0.12-cp313-cp313-win_amd64.whl.metadata (2.2 kB)\n",
      "  Collecting thinc<8.4.0,>=8.3.0\n",
      "    Using cached thinc-8.3.6-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "  Collecting numpy<2.1.0,>=2.0.0\n",
      "    Using cached numpy-2.0.2.tar.gz (18.9 MB)\n",
      "    Installing build dependencies: started\n",
      "    Installing build dependencies: finished with status 'done'\n",
      "    Getting requirements to build wheel: started\n",
      "    Getting requirements to build wheel: finished with status 'done'\n",
      "    Installing backend dependencies: started\n",
      "    Installing backend dependencies: finished with status 'done'\n",
      "    Preparing metadata (pyproject.toml): started\n",
      "    Preparing metadata (pyproject.toml): finished with status 'error'\n",
      "    error: subprocess-exited-with-error\n",
      "  \n",
      "    Preparing metadata (pyproject.toml) did not run successfully.\n",
      "    exit code: 1\n",
      "  \n",
      "    [21 lines of output]\n",
      "    + E:\\python.exe C:\\Users\\Administrator\\AppData\\Local\\Temp\\pip-install-pr2a6tz5\\numpy_405c2ed7c94b4cad903ede3c418fa22f\\vendored-meson\\meson\\meson.py setup C:\\Users\\Administrator\\AppData\\Local\\Temp\\pip-install-pr2a6tz5\\numpy_405c2ed7c94b4cad903ede3c418fa22f C:\\Users\\Administrator\\AppData\\Local\\Temp\\pip-install-pr2a6tz5\\numpy_405c2ed7c94b4cad903ede3c418fa22f\\.mesonpy-pdpermhz -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=C:\\Users\\Administrator\\AppData\\Local\\Temp\\pip-install-pr2a6tz5\\numpy_405c2ed7c94b4cad903ede3c418fa22f\\.mesonpy-pdpermhz\\meson-python-native-file.ini\n",
      "    The Meson build system\n",
      "    Version: 1.4.99\n",
      "    Source dir: C:\\Users\\Administrator\\AppData\\Local\\Temp\\pip-install-pr2a6tz5\\numpy_405c2ed7c94b4cad903ede3c418fa22f\n",
      "    Build dir: C:\\Users\\Administrator\\AppData\\Local\\Temp\\pip-install-pr2a6tz5\\numpy_405c2ed7c94b4cad903ede3c418fa22f\\.mesonpy-pdpermhz\n",
      "    Build type: native build\n",
      "    Project name: NumPy\n",
      "    Project version: 2.0.2\n",
      "    WARNING: Failed to activate VS environment: Could not find C:\\Program Files (x86)\\Microsoft Visual Studio\\Installer\\vswhere.exe\n",
      "  \n",
      "    ..\\meson.build:1:0: ERROR: Unknown compiler(s): [['icl'], ['cl'], ['cc'], ['gcc'], ['clang'], ['clang-cl'], ['pgcc']]\n",
      "    The following exception(s) were encountered:\n",
      "    Running `icl \"\"` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "    Running `cl /?` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "    Running `cc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "    Running `gcc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "    Running `clang --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "    Running `clang-cl /?` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "    Running `pgcc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "  \n",
      "    A full log can be found at C:\\Users\\Administrator\\AppData\\Local\\Temp\\pip-install-pr2a6tz5\\numpy_405c2ed7c94b4cad903ede3c418fa22f\\.mesonpy-pdpermhz\\meson-logs\\meson-log.txt\n",
      "    [end of output]\n",
      "  \n",
      "    note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  error: metadata-generation-failed\n",
      "  \n",
      "  Encountered error while generating package metadata.\n",
      "  \n",
      "  See above for output.\n",
      "  \n",
      "  note: This is an issue with the package mentioned above, not pip.\n",
      "  hint: See above for details.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "pip subprocess to install build dependencies did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "657d43b8-fea6-4560-b8da-ccca13028662",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (581980377.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[100]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpython -m spacy download en_core_web_sm\u001b[39m\n              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fdcc9b23-356d-4f09-9627-b39729e98ea6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[112]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m nlp = \u001b[43mspacy\u001b[49m.load(\u001b[33m\"\u001b[39m\u001b[33men_core_web_sm\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'spacy' is not defined"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dfd23d-e6ea-4d9d-9445-387365c8b3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "description = [\n",
    "    \"A 12-year-old boy tries to scare away his mother's new boyfriend, a police officer, but his plan backfires, exposing them to a criminal network.\",\n",
    "    \"A businessman starts his own company and travels to Europe with his associates to close an important deal, facing unexpected challenges.\",\n",
    "    \"A tough hockey player is sentenced to serve as a real-life tooth fairy for a week after discouraging a child's dreams.\",\n",
    "    \"In this sequel, a couple deals with the arrival of a new baby, leading to sibling rivalry and humorous situations.\",\n",
    "    \"Two friends embark on a road trip seeking a fresh start but become entangled in a criminal scheme.\",\n",
    "    \"A young man's deceased girlfriend returns from the dead, leading to unexpected and bizarre consequences.\",\n",
    "    \"After a painful breakup, a man vows to abstain from any sexual activity for Lent, but complications arise when he meets someone new.\",\n",
    "    \"A group of modern-day Robin Hoods recruits a renowned thief to help them pull off a heist targeting a corrupt businessman.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a10e19-1bf3-4bae-a454-e7132cc12380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_clean(text):\n",
    "    doc = nlp(text)  # Text ko spaCy ke model mein bhejte hain\n",
    "    clean_words = []\n",
    "\n",
    "    for word in doc:\n",
    "        if word.is_alpha and not word.is_stop:  # Sirf alphabets aur stopwords hatao\n",
    "            clean_words.append(word.lemma_)     # Base form (lemma) add karo\n",
    "\n",
    "    return clean_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a76473-bf73-4dac-81de-8fecb74a3898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "sentence = \"The cats are running in the garden happily.\"\n",
    "\n",
    "print(spacy_clean(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822b62af-e1da-45c1-a07b-d55387887cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spacy_clean(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28af9de-b090-4a10-b011-19ce0bdfec8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "84847203-1e51-41d8-967b-e41ec83d2934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         description\n",
      "0  A 12-year-old boy tries to scare away his moth...\n",
      "1  A businessman starts his own company and trave...\n",
      "2  A tough hockey player is sentenced to serve as...\n",
      "3  In this sequel, a couple deals with the arriva...\n",
      "4  Two friends embark on a road trip seeking a fr...\n",
      "5  A young man's deceased girlfriend returns from...\n",
      "6  After a painful breakup, a man vows to abstain...\n",
      "7  A group of modern-day Robin Hoods recruits a r...\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cc1b343c-4cd8-4350-af63-782e5d7e06fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         description\n",
      "0  A 12-year-old boy tries to scare away his moth...\n",
      "1  A businessman starts his own company and trave...\n",
      "2  A tough hockey player is sentenced to serve as...\n",
      "3  In this sequel, a couple deals with the arriva...\n",
      "4  Two friends embark on a road trip seeking a fr...\n",
      "5  A young man's deceased girlfriend returns from...\n",
      "6  After a painful breakup, a man vows to abstain...\n",
      "7  A group of modern-day Robin Hoods recruits a r...\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768290a6-24d0-4943-9a59-4a35435a4dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
